{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c43dd5f-cc62-40dd-bb89-646b99766dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydantic_ai in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (0.0.22)\n",
      "Requirement already satisfied: pydantic-ai-slim==0.0.22 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.0.22)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.2.2)\n",
      "Requirement already satisfied: griffe>=1.3.2 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.5.6)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.28.1)\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (3.5.3)\n",
      "Requirement already satisfied: pydantic-graph==0.0.22 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.0.22)\n",
      "Requirement already satisfied: pydantic>=2.10 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.10.6)\n",
      "Requirement already satisfied: anthropic>=0.40.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.45.2)\n",
      "Requirement already satisfied: cohere>=5.13.11 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (5.13.11)\n",
      "Requirement already satisfied: groq>=0.12.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.18.0)\n",
      "Requirement already satisfied: mistralai>=1.2.5 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.5.0)\n",
      "Requirement already satisfied: openai>=1.59.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.61.1)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.38.0)\n",
      "Requirement already satisfied: requests>=2.32.3 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (4.12.2)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.27.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.21.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.32.0.20241016)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (4.9)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from griffe>=1.3.2->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.14.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.9.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from openai>=1.59.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.0.22->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2.2.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (0.28.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from typing-inspect>=0.9.0->mistralai>=1.2.5->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (1.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kaepa\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.22->pydantic_ai) (6.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pydantic-ai-slim 0.0.22 does not provide the extra 'graph'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install backend dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [31 lines of output]\n",
      "  Collecting distribute\n",
      "    Downloading distribute-0.7.3.zip (145 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [6 lines of output]\n",
      "    usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "       or: setup.py --help [cmd1 cmd2 ...]\n",
      "       or: setup.py --help-commands\n",
      "       or: setup.py cmd --help\n",
      "  \n",
      "    error: invalid command 'dist_info'\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install backend dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic_ai\n",
    "!pip install python-dotenv\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "660c0fc8-2e3d-4214-a536-b451d9dcd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext, Tool, ModelRetry\n",
    "from pydantic_ai.models.openai import OpenAIModel, AsyncOpenAI\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8462e98-7d45-442b-b20c-44bb6cc5ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c016f81c-ac05-4eb6-86f0-fd23fd1091df",
   "metadata": {},
   "source": [
    "# USING OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300b3cd-7d7e-44bf-af6d-5821c8ef2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='',\n",
    ")\n",
    "# Create the agent\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='llama3.2',\n",
    "    openai_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "564d12f4-37e7-4c8a-9dd3-38b94ab6a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_agent = Agent(\n",
    "    model=ollama_model,\n",
    "    system_prompt=\"You are helpful customer support agent. Be concise and friendly\",\n",
    ")\n",
    "\n",
    "result = basic_agent.run_sync('How can I track my order #12345?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f4dc321-ed18-4762-860e-38f9698973cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To track your order #12345, please follow these steps:\n",
      "\n",
      "1. Go to our website and sign in to your account.\n",
      "2. Click on \"Order Tracking\" at the top of the page.\n",
      "3. Enter your order number (#12345) and click \"Search\".\n",
      "4. You will be redirected to the shipping carrier's tracking page.\n",
      "\n",
      "If you're unable to track it online, please contact our customer service team, and we'll be happy to assist you further!\n"
     ]
    }
   ],
   "source": [
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f79054-3c96-4f74-8acf-61b056dd91e3",
   "metadata": {},
   "source": [
    "# USING GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd46bdd6-6ff4-4e4c-be94-afc1379f5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf785e28-394e-4033-8d61-05439160a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'google-gla:gemini-1.5-flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3939324a-27a1-43f2-a80c-5d9a37dbacac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    This example demonstrates the basic usage of PydanticAI agents.\\n    Key Concepts:\\n        - Creating a basic agent with a system prompt\\n        - Running synchronous queries\\n        - Accessing response data, message history, and costs\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This example demonstrates the basic usage of PydanticAI agents.\n",
    "    Key Concepts:\n",
    "        - Creating a basic agent with a system prompt\n",
    "        - Running synchronous queries\n",
    "        - Accessing response data, message history, and costs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1a665cb-91a3-4e12-a8e3-de6f8051c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are helpful customer support agent. Be concise and friendly\",\n",
    ")\n",
    "\n",
    "\n",
    "result = basic_agent.run_sync('How can I track my order #12345?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0083727-baa8-4915-9294-326d1f664d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there!  You can track your order #12345 here: [insert tracking link here].  Let me know if you have any other questions!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83418d40-6797-4161-a761-c5528c1b768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelRequest(parts=[SystemPromptPart(content='You are helpful customer support agent. Be concise and friendly', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='How can I track my order #12345?', timestamp=datetime.datetime(2025, 2, 7, 9, 35, 11, 117068, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='Hi there!  You can track your order #12345 here: [insert tracking link here].  Let me know if you have any other questions!\\n', part_kind='text')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 7, 9, 35, 12, 622610, tzinfo=datetime.timezone.utc), kind='response')]\n"
     ]
    }
   ],
   "source": [
    "print(result.all_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40d79d8a-e190-40f9-b767-c6c6250a3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result.cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14f23a13-b152-42ab-bd39-868ad7824606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your previous question was how to track your order #12345.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = basic_agent.run_sync(\n",
    "    user_prompt=\"What was my previous question?\",\n",
    "    message_history=result.new_messages()\n",
    ")\n",
    "\n",
    "print(result2.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6d0d2-59f5-4314-959e-bf8178ece883",
   "metadata": {},
   "source": [
    "# AGENT WITH STRUCTURED RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14824af-9d82-4368-b341-7d2ae2b1942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This example shows how to get structured, type-safe responses from the agent.\n",
    "    Key concepts:\n",
    "        - Using Pydantic models to define response structure\n",
    "        - Type validation and safety\n",
    "        - Field descriptions for better model understanding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48d8d267-d6ca-4ac8-ab52-eba6b512c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of \n",
    "\n",
    "\"\"\"\n",
    "    @dataclass\n",
    "    Model\n",
    "        - type hints (for ide)\n",
    "        - data validation\n",
    "        - serialization (from json | to json)\n",
    "        - built-in\n",
    "\n",
    "    Model(BaseModel)\n",
    "        - type hints (for ide)\n",
    "        - data validation\n",
    "        - serialization (from json | to json)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResponseModel():\n",
    "    response: str\n",
    "    needs_escalation: str\n",
    "    follow_up_required: str\n",
    "    sentiment: str = Field(description=\"Customer sentiment analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8bc73fe-1bc0-4120-82b6-4755dc649fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseModel -> use Pydantic's validation, serialization from other utilities.\n",
    "class ResponseModel(BaseModel):\n",
    "    \"\"\" Structured response with metada.\"\"\"\n",
    "    response: str\n",
    "    needs_escalation: str\n",
    "    follow_up_required: str\n",
    "    sentiment: str = Field(description=\"Customer sentiment analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f3f8fee-c373-4a16-b109-9ba8181e4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = Agent(\n",
    "    model=model,\n",
    "    result_type=ResponseModel,\n",
    "    system_prompt=(\n",
    "        \"You are an intelligent customer support agent.\"\n",
    "        \"Analyze queries carefully and provide structured responses.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = agent1.run_sync(\"How can I track my order #12345?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee630a4-3b06-430b-9a40-3bb61bf6872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249af8a-a47c-4eeb-b255-6c8891a36ba4",
   "metadata": {},
   "source": [
    "# AGENT WITH STRUCTURED RESPONSE AND DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "36929fbc-dbe0-4bf4-8077-736c402c031e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    This example demonstrates how to use dependencies and context in agents.\\n    Key concepts:\\n        - Defining complex data models with Pydantic\\n        - Injectinng runtime dependencies\\n        - Using dynamic system prompts\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This example demonstrates how to use dependencies and context in agents.\n",
    "    Key concepts:\n",
    "        - Defining complex data models with Pydantic\n",
    "        - Injectinng runtime dependencies\n",
    "        - Using dynamic system prompts\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aff3e48e-97b9-4ccf-86be-782418648000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class Order(BaseModel):\n",
    "    \"\"\" Structure for order details \"\"\"\n",
    "    order_id: str\n",
    "    status: str\n",
    "    items: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efe63909-08a9-4b06-88a2-ed5d20a9d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerDetails(BaseModel):\n",
    "    \"\"\" Structure for incoming customer queries\"\"\"\n",
    "\n",
    "    customer_id: str\n",
    "    name: str\n",
    "    email: str\n",
    "    orders: Optional[List[Order]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91e80adb-8d4b-4448-90d2-5788d24e5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retries -> default = 1\n",
    "\n",
    "agent3 = Agent(\n",
    "    model=model,\n",
    "    result_type=ResponseModel,\n",
    "    deps_type=CustomerDetails,\n",
    "    retries=3,\n",
    "    system_prompt=(\n",
    "        \"You are an intelligent customer support agent. \"\n",
    "        \"Analyze queries carefully and provide structured responses. \"\n",
    "        \"Always great the customer and provide a helpful response. \"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3931c4c3-4724-44dc-91a9-91d12f576051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(data, indent=0):\n",
    "    markdown = \"\"\n",
    "    \n",
    "    # Check if the data is an instance of BaseModel and dump the model\n",
    "    if isinstance(data, BaseModel):\n",
    "        data = data.model_dump()\n",
    "    \n",
    "    # Handle data if it's a dictionary\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            markdown += f\"{'#' * (indent + 2)} {key.upper()}\\n\"\n",
    "            if isinstance(value, (dict, list, BaseModel)):\n",
    "                markdown += to_markdown(value, indent + 1)\n",
    "            else:\n",
    "                markdown += f\"{value}\\n\\n\"\n",
    "    \n",
    "    # Handle data if it's a list\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, (dict, list, BaseModel)):\n",
    "                markdown += to_markdown(item, indent + 1)\n",
    "            else:\n",
    "                markdown += f\"- {item}\\n\"\n",
    "        markdown += \"\\n\"\n",
    "    \n",
    "    # Handle other types of data (such as strings, integers, etc.)\n",
    "    else:\n",
    "        markdown += f\"{data}\\n\\n\"\n",
    "    \n",
    "    return markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ba218ad-ae68-4132-ae1c-08a3f05d1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator\n",
    "# Add dynamic system prompt based on dependencies\n",
    "# CustomerDetails -> dependency\n",
    "# str -> return type\n",
    "@agent3.system_prompt\n",
    "async def add_customer_name(ctx: RunContext[CustomerDetails]) -> str:\n",
    "    return f\"Customer details: {to_markdown(ctx.deps)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7486410-d6e2-493b-a193-9f76a2a907c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = CustomerDetails(\n",
    "    customer_id=\"1\",\n",
    "    name=\"John Doe\",\n",
    "    email=\"john.doe@example.com\",\n",
    "    orders=[\n",
    "        Order(\n",
    "            order_id=\"12345\",\n",
    "            status=\"shipped\",\n",
    "            items = [\n",
    "                \"Blue Jeans\",\n",
    "                \"T-Shirt\"\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ed8ffe0-3e5b-40d6-8df1-8fd9f49235b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent3.run_sync(user_prompt=\"What did I order?\", deps=customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8485b3a8-32f6-4247-9e8d-e34e15740e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='You are an intelligent customer support agent. Analyze queries carefully and provide structured responses. Always great the customer and provide a helpful response. ', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='What did I order?', timestamp=datetime.datetime(2025, 2, 7, 9, 59, 38, 973818, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'needs_escalation': 'false', 'follow_up_required': 'false', 'sentiment': 'positive', 'response': 'You ordered a Blue Jeans and a T-Shirt.'}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 7, 9, 59, 40, 615397, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 7, 9, 59, 40, 616397, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80ca112c-46c0-4c28-9125-68477edb1fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"You ordered a Blue Jeans and a T-Shirt.\",\n",
      "  \"needs_escalation\": \"false\",\n",
      "  \"follow_up_required\": \"false\",\n",
      "  \"sentiment\": \"positive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7ebf0337-2d73-47a7-931f-b8cf1eaa9227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Details:\n",
      "Name: John Doe\n",
      "Email: john.doe@example.com\n",
      "\n",
      "Response Details:\n",
      "You ordered Blue Jeans and a T-Shirt.\n",
      "\n",
      "Status:\n",
      "Follow-up Required: false\n",
      "Needs Escalation: false\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Customer Details:\\n\"\n",
    "    f\"Name: {customer.name}\\n\"\n",
    "    f\"Email: {customer.email}\\n\\n\"\n",
    "    \"Response Details:\\n\"\n",
    "    f\"{response.data.response}\\n\\n\"\n",
    "    \"Status:\\n\"\n",
    "    f\"Follow-up Required: {response.data.follow_up_required}\\n\"\n",
    "    f\"Needs Escalation: {response.data.needs_escalation}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a12fa7-daa7-47aa-a11d-9727845a3b55",
   "metadata": {},
   "source": [
    "# Agent with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ce8ed92e-5ab3-427c-9b31-d893bf53ac74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    This example shows how to enhance agents with custom tools.\\n    Key Concepts:\\n        - Creating and registering tools\\n        - Accessing context in tools\\n'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This example shows how to enhance agents with custom tools.\n",
    "    Key Concepts:\n",
    "        - Creating and registering tools\n",
    "        - Accessing context in tools\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "82d54f34-d967-4711-a07e-5b6c950192ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "shipping_info_db: Dict[str, str] = {\n",
    "    \"12345\": \"Shipped on 2024-12-12\",\n",
    "    \"67890\": \"Out for delivery\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4704e88a-7f51-402f-9eea-d43197a8d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shipping_info(ctx: RunContext[CustomerDetails]) -> str:\n",
    "    \"\"\" Get the customer's shipping information. \"\"\"\n",
    "    return shipping_info_db[ctx.deps.orders[0].order_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a1f8d22-0281-4ec7-beca-739d4e591a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent4 = Agent(\n",
    "    model=model,\n",
    "    result_type=ResponseModel,\n",
    "    deps_type=CustomerDetails,\n",
    "    retries=3,\n",
    "    system_prompt=(\n",
    "        \"You are an intelligent customer support agent. \"\n",
    "        \"Analyze queries carefully and provide structured responses. \"\n",
    "        \"Use tools to look up relevant information.\"\n",
    "        \"Always great the customer and provide a helpful response.\"\n",
    "    ),\n",
    "    tools=[Tool(get_shipping_info, takes_ctx=True)], # Add tool via kwarg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "be7ec8a8-0a2b-4129-86a9-bc528ab7f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent4.system_prompt\n",
    "async def add_customer_name(ctx: RunContext[CustomerDetails]) -> str:\n",
    "    return f\"Customer details: {to_markdown(ctx.deps)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c132c220-7984-46be-8aaa-20e8626ea950",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent4.run_sync(\n",
    "    user_prompt=\"What's the status of my last order?\", deps = customer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "21830762-6121-4690-b5ab-590fce1c833a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='You are an intelligent customer support agent. Analyze queries carefully and provide structured responses. Use tools to look up relevant information.Always great the customer and provide a helpful response.', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='Customer details: ## CUSTOMER_ID\\n1\\n\\n## NAME\\nJohn Doe\\n\\n## EMAIL\\njohn.doe@example.com\\n\\n## ORDERS\\n#### ORDER_ID\\n12345\\n\\n#### STATUS\\nshipped\\n\\n#### ITEMS\\n- Blue Jeans\\n- T-Shirt\\n\\n\\n', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content=\"What's the status of my last order?\", timestamp=datetime.datetime(2025, 2, 6, 13, 32, 50, 672305, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='get_shipping_info', args={}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 6, 13, 32, 52, 247105, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='get_shipping_info', content='Shipped on 2024-12-12', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 6, 13, 32, 52, 250105, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'response': 'Your order (12345) has shipped on 2024-12-12.', 'sentiment': 'positive', 'follow_up_required': 'false', 'needs_escalation': 'false'}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 6, 13, 32, 53, 132225, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 6, 13, 32, 53, 133225, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6ee11078-9393-4ecd-89f4-924f6e10aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"Your order (12345) has shipped on 2024-12-12.\",\n",
      "  \"needs_escalation\": \"false\",\n",
      "  \"follow_up_required\": \"false\",\n",
      "  \"sentiment\": \"positive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9ee38-8b1e-4f04-bd4e-c3407900a7ae",
   "metadata": {},
   "source": [
    "# Agent with Reflection and Self-Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f41ddea4-6795-4917-879d-c6d0b1237fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    This example demonstrates advanced agent capabilities with self-correction.\\n    Key concepts:\\n        - Implementing self-reflection\\n        - Handling erros gracefully with retries\\n        - Using ModelRetry for automatic retries\\n        - Decorator-based tool registration\\n'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This example demonstrates advanced agent capabilities with self-correction.\n",
    "    Key concepts:\n",
    "        - Implementing self-reflection\n",
    "        - Handling erros gracefully with retries\n",
    "        - Using ModelRetry for automatic retries\n",
    "        - Decorator-based tool registration\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e96a7668-9299-4cf3-be5b-4691316ae171",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_info_db: Dict[str, str] = {\n",
    "    \"#12345\": \"Shipped on 2024-12-12\",\n",
    "    \"#67890\": \"Out for delivery\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8baf9100-6893-4672-a2bc-9b8f1372ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = CustomerDetails(\n",
    "    customer_id=\"1\",\n",
    "    name=\"John Doe\",\n",
    "    email=\"john.doe@example.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "134cd907-8674-415e-a678-6a4dc64f1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent5 = Agent(\n",
    "    model=model,\n",
    "    result_type=ResponseModel,\n",
    "    deps_type=CustomerDetails,\n",
    "    retries=3,\n",
    "    system_prompt=(\n",
    "        \"You are an intelligent customer support agent. \"\n",
    "        \"Analyze queries carefully and provide structured responses. \"\n",
    "        \"Use tools to look up relevant information. \"\n",
    "        \"Always greet the customer and provide a helpful response. \"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e67aa3c9-98fd-4603-8a3c-ac5f7d352d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent5.tool_plain() # Add plain tool via decorator\n",
    "def get_shipping_status(order_id: str) -> str:\n",
    "    \"\"\" Get the shipping status for a given order ID.\"\"\"\n",
    "    shipping_status = shipping_info_db.get(order_id)\n",
    "    if shipping_status is None:\n",
    "        raise ModelRetry(\n",
    "            f\"No shipping information found for order ID {order_id}.\"\n",
    "            \"Make sure the Order ID starts with a #: e.g. #12345 \"\n",
    "            \"Self correct this is needed and try again.\"\n",
    "        )\n",
    "    return shipping_info_db[order_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "040e8c9d-6cd4-498c-a19b-fb2f80e05666",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent5.run_sync(\n",
    "    user_prompt=\"What's the status of my last order 12345\", deps=customer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2480f4ec-7ac4-42c4-9cf6-1012b5adc5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='You are an intelligent customer support agent. Analyze queries carefully and provide structured responses. Use tools to look up relevant information. Always greet the customer and provide a helpful response. ', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content=\"What's the status of my last order 12345\", timestamp=datetime.datetime(2025, 2, 6, 13, 45, 18, 517627, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='get_shipping_status', args={'order_id': '12345'}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 6, 13, 45, 20, 114181, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[RetryPromptPart(content='No shipping information found for order ID 12345.Make sure the Order ID starts with a #: e.g. #12345 Self correct this is needed and try again.', tool_name='get_shipping_status', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 6, 13, 45, 20, 115181, tzinfo=datetime.timezone.utc), part_kind='retry-prompt')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'needs_escalation': 'false', 'follow_up_required': 'true', 'sentiment': 'neutral', 'response': 'I looked up order #12345, but there is no shipping information available. Please ensure that the order ID is correct and try again.'}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 6, 13, 45, 21, 109757, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 6, 13, 45, 21, 110757, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "71e00209-ed73-4ed2-8dd9-9af1f82f14d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"I am sorry, I cannot find your order information. Please provide a valid order ID.\",\n",
      "  \"needs_escalation\": \"false\",\n",
      "  \"follow_up_required\": \"true\",\n",
      "  \"sentiment\": \"neutral\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5870f2-bea7-4864-9f87-00fc7a04d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
